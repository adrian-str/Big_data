{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('CC').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('../data/customer_churn.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date='2013-08-30 07:00:40', Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1),\n",
       " Row(Names='Kevin Mueller', Age=41.0, Total_Purchase=11916.22, Account_Manager=0, Years=6.5, Num_Sites=11.0, Onboard_date='2013-08-13 00:38:46', Location='6157 Frank Gardens Suite 019 Carloshaven, RI 17756', Company='Wilson PLC', Churn=1),\n",
       " Row(Names='Eric Lozano', Age=38.0, Total_Purchase=12884.75, Account_Manager=0, Years=6.67, Num_Sites=12.0, Onboard_date='2016-06-29 06:20:07', Location='1331 Keith Court Alyssahaven, DE 90114', Company='Miller, Johnson and Wallace', Churn=1),\n",
       " Row(Names='Phillip White', Age=42.0, Total_Purchase=8010.76, Account_Manager=0, Years=6.71, Num_Sites=10.0, Onboard_date='2014-04-22 12:43:12', Location='13120 Daniel Mount Angelabury, WY 30645-4695', Company='Smith Inc', Churn=1),\n",
       " Row(Names='Cynthia Norton', Age=37.0, Total_Purchase=9191.58, Account_Manager=0, Years=5.56, Num_Sites=9.0, Onboard_date='2016-01-19 15:31:15', Location='765 Tricia Row Karenshire, MH 71730', Company='Love-Jones', Churn=1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "date_indexer=StringIndexer(inputCol='Onboard_date',outputCol='date_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind=date_indexer.fit(df).transform(df)\n",
    "assembler = VectorAssembler(inputCols=['Age','Total_Purchase','Account_Manager','Years','Num_Sites','date_index'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|Churn|\n",
      "+--------------------+-----+\n",
      "|[42.0,11066.8,0.0...|    1|\n",
      "|[41.0,11916.22,0....|    1|\n",
      "|[38.0,12884.75,0....|    1|\n",
      "|[42.0,8010.76,0.0...|    1|\n",
      "|[37.0,9191.58,0.0...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features=assembler.transform(df_ind)\n",
    "data=features.select(['features','Churn'])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=data.randomSplit(seed=0,weights=[0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression \n",
    "logR=LogisticRegression(labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model=logR.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation=log_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC is:  0.918825812712276\n",
      "Accuracy is:  0.8978102189781022\n"
     ]
    }
   ],
   "source": [
    "print(\"Area under ROC is: \",evaluation.areaUnderROC)\n",
    "print(\"Accuracy is: \",evaluation.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = log_model.evaluate(test).predictions.select('Churn', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC is:  0.8049490538573507\n",
      "Accuracy is:  0.8978102189781022\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "evalBC = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Churn',metricName=\"areaUnderROC\")\n",
    "evalMC=MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='Churn', metricName='accuracy')\n",
    "print(\"Area under ROC is: \",evalBC.evaluate(predictionAndLabels))\n",
    "print(\"Accuracy is: \",evalMC.evaluate(predictionAndLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without \"Account_Manager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC is:  0.9161086851043186\n",
      "Accuracy is:  0.9087591240875912\n"
     ]
    }
   ],
   "source": [
    "df_ind=date_indexer.fit(df).transform(df)\n",
    "assembler2 = VectorAssembler(inputCols=['Age','Total_Purchase','Years','Num_Sites','date_index'],outputCol='features')\n",
    "features2=assembler2.transform(df_ind)\n",
    "data2=features2.select(['features','Churn'])\n",
    "train2,test2=data2.randomSplit(seed=0,weights=[0.7,0.3])\n",
    "log_model2=logR.fit(train2)\n",
    "evaluation2=log_model2.evaluate(test2)\n",
    "print(\"Area under ROC is: \",evaluation2.areaUnderROC)\n",
    "print(\"Accuracy is: \",evaluation2.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC is:  0.811499272197962\n",
      "Accuracy is:  0.9087591240875912\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = log_model2.evaluate(test2).predictions.select('Churn', 'prediction')\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "evalBC = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Churn',metricName=\"areaUnderROC\")\n",
    "evalMC=MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='Churn', metricName='accuracy')\n",
    "print(\"Area under ROC is: \",evalBC.evaluate(predictionAndLabels))\n",
    "print(\"Accuracy is: \",evalMC.evaluate(predictionAndLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are better without the \"Account_Manager\" variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

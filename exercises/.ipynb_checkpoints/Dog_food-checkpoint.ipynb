{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DF\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('../data/dog_food.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Spoiled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>5.53469387755102</td>\n",
       "      <td>5.504081632653061</td>\n",
       "      <td>9.126530612244897</td>\n",
       "      <td>5.579591836734694</td>\n",
       "      <td>0.2857142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.9515204234399057</td>\n",
       "      <td>2.8537966089662063</td>\n",
       "      <td>2.0555451971054275</td>\n",
       "      <td>2.8548369309982857</td>\n",
       "      <td>0.45221563164613465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                   A                   B                   C  \\\n",
       "0   count                 490                 490                 490   \n",
       "1    mean    5.53469387755102   5.504081632653061   9.126530612244897   \n",
       "2  stddev  2.9515204234399057  2.8537966089662063  2.0555451971054275   \n",
       "3     min                   1                   1                 5.0   \n",
       "4     max                  10                  10                14.0   \n",
       "\n",
       "                    D              Spoiled  \n",
       "0                 490                  490  \n",
       "1   5.579591836734694   0.2857142857142857  \n",
       "2  2.8548369309982857  0.45221563164613465  \n",
       "3                   1                  0.0  \n",
       "4                  10                  1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "|  4|  2|12.0|  1|    1.0|\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "dtc = DecisionTreeClassifier(labelCol='Spoiled')\n",
    "rfc = RandomForestClassifier(numTrees = 100,labelCol='Spoiled')\n",
    "gbt = GBTClassifier(labelCol='Spoiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler=VectorAssembler(inputCols=['A','B','C','D'],outputCol='features')\n",
    "data=assembler.transform(df)\n",
    "train,test=data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train)\n",
    "rfc_model = rfc.fit(train)\n",
    "gbt_model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test)\n",
    "rfc_preds = rfc_model.transform(test)\n",
    "gbt_preds = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator \n",
    "evalMC = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='Spoiled', metricName='accuracy')\n",
    "evalBC = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Spoiled',metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC accuracy: 0.9709302325581395\n",
      "DTC area Under ROC: 0.9803149606299212\n",
      "RFC accuracy: 1.0\n",
      "RFC area Under ROC: 1.0\n",
      "GBT accuracy: 0.9709302325581395\n",
      "GBT area Under ROC: 0.9803149606299212\n"
     ]
    }
   ],
   "source": [
    "print(f'DTC accuracy: {evalMC.evaluate(dtc_preds)}') \n",
    "print(f'DTC area Under ROC: {evalBC.evaluate(dtc_preds)}') \n",
    "print(f'RFC accuracy: {evalMC.evaluate(rfc_preds)}')\n",
    "print(f'RFC area Under ROC: {evalBC.evaluate(rfc_preds)}')\n",
    "print(f'GBT accuracy: {evalMC.evaluate(gbt_preds)}')\n",
    "print(f'GBT area Under ROC: {evalBC.evaluate(gbt_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best model to check for the feature importances is Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of A is: 0.030750311804022618\n",
      "Importance of B is: 0.044804564084640834\n",
      "Importance of C is: 0.8935639337298104\n",
      "Importance of D is: 0.03088119038152623\n"
     ]
    }
   ],
   "source": [
    "print(f'Importance of A is: {rfc_model.featureImportances[0]}')\n",
    "print(f'Importance of B is: {rfc_model.featureImportances[1]}')\n",
    "print(f'Importance of C is: {rfc_model.featureImportances[2]}')\n",
    "print(f'Importance of D is: {rfc_model.featureImportances[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemical preservative C has the biggest effect on the dog food being spoiled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
